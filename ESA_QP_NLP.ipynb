{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f87f2f",
   "metadata": {},
   "source": [
    "### XXXX-2022: END SEMESTER ASSESSMENT (ESA) \n",
    "## M TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n",
    "\n",
    "#### UE20CS933 - NATURAL LANGUAGE PROCESSING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d2e19",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from gensim.parsing.preprocessing import PorterStemmer, remove_stopwords\n",
    "import string \n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eea2c4",
   "metadata": {},
   "source": [
    "## Section B\n",
    "### 2. Use the data.csv dataset as provided in the notebook as Pandas DataFrame and   process it as questioned below.\n",
    "\n",
    "#### Dataset \n",
    "Airline Sentiment dataset is provide as pandas dataframe. Using python NLP libraires process the dataset as questioned below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9890979d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9be4a4",
   "metadata": {},
   "source": [
    "### 2.a. Create a new Pandas DataFrame by fetching two columns 'text’ and 'airline_sentiment' from data.csv.  (Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecfc5b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "0                    @VirginAmerica What @dhepburn said.           neutral\n",
       "1      @VirginAmerica plus you've added commercials t...          positive\n",
       "2      @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3      @VirginAmerica it's really aggressive to blast...          negative\n",
       "4      @VirginAmerica and it's a really big bad thing...          negative\n",
       "...                                                  ...               ...\n",
       "14635  @AmericanAir thank you we got on a different f...          positive\n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...          negative\n",
       "14637  @AmericanAir Please bring American Airlines to...           neutral\n",
       "14638  @AmericanAir you have my money, you change my ...          negative\n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...           neutral\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[['text','airline_sentiment']].copy(deep=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe69ab2",
   "metadata": {},
   "source": [
    "### 2.b. Clean the 'text' columns as questioned below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643cef6",
   "metadata": {},
   "source": [
    "#### 2.b.(i) Convert all text to lower case ( Marks- 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ad07b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      @virginamerica what @dhepburn said.\n",
       "1        @virginamerica plus you've added commercials t...\n",
       "2        @virginamerica i didn't today... must mean i n...\n",
       "3        @virginamerica it's really aggressive to blast...\n",
       "4        @virginamerica and it's a really big bad thing...\n",
       "                               ...                        \n",
       "14635    @americanair thank you we got on a different f...\n",
       "14636    @americanair leaving over 20 minutes late flig...\n",
       "14637    @americanair please bring american airlines to...\n",
       "14638    @americanair you have my money, you change my ...\n",
       "14639    @americanair we have 8 ppl so we need 2 know h...\n",
       "Name: cleaned_text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(lower_text)\n",
    "df['cleaned_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca8b166",
   "metadata": {},
   "source": [
    "#### 2.b.(ii)  Remove the URLs (http & www) from text ( Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b4b022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      @virginamerica what @dhepburn said.\n",
       "1        @virginamerica plus you've added commercials t...\n",
       "2        @virginamerica i didn't today... must mean i n...\n",
       "3        @virginamerica it's really aggressive to blast...\n",
       "4        @virginamerica and it's a really big bad thing...\n",
       "                               ...                        \n",
       "14635    @americanair thank you we got on a different f...\n",
       "14636    @americanair leaving over 20 minutes late flig...\n",
       "14637    @americanair please bring american airlines to...\n",
       "14638    @americanair you have my money, you change my ...\n",
       "14639    @americanair we have 8 ppl so we need 2 know h...\n",
       "Name: cleaned_text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: regular expression for URLs  matching is 'https?://\\S+|www\\.\\S+' \n",
    "def remove_http_www(text):\n",
    "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(remove_http_www)\n",
    "df['cleaned_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1623fe",
   "metadata": {},
   "source": [
    "#### 2.b.(iii).  Remove stopwords from text.  ( Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e08e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any of nltk or gensim can be used\n",
    "def drop_stop_words(text):\n",
    "    engstop_words = stopwords.words('english')\n",
    "    tokens = text.split()\n",
    "    tokens = [x for x in tokens if x not in engstop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "drop_stop_words(\"I am working with your student to train all the batches on python\")\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(drop_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884da79",
   "metadata": {},
   "source": [
    "#### 2.b.(iv) Remove punctuations from text. (Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc60d427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              virginamerica dhepburn said\n",
       "1        virginamerica plus added commercials experienc...\n",
       "2        virginamerica today must mean need take anothe...\n",
       "3        virginamerica really aggressive blast obnoxiou...\n",
       "4                       virginamerica really big bad thing\n",
       "                               ...                        \n",
       "14635       americanair thank got different flight chicago\n",
       "14636    americanair leaving 20 minutes late flight war...\n",
       "14637    americanair please bring american airlines bla...\n",
       "14638    americanair money change flight answer phones ...\n",
       "14639    americanair 8 ppl need 2 know many seats next ...\n",
       "Name: cleaned_text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: refer string.punctuation to fetch all punctuations\n",
    "text = \"I want to remove these '!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~' and these '!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\"\n",
    "\n",
    "def drop_punctuations(text):\n",
    "    return re.sub(r\"[^\\w\\s]\", '', text)\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(drop_punctuations)\n",
    "df['cleaned_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac2208",
   "metadata": {},
   "source": [
    "### 2.c. Fetch the top six most frequently used words from the text corpus (Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eccd212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>united</th>\n",
       "      <td>4143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flight</th>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usairways</th>\n",
       "      <td>3051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>americanair</th>\n",
       "      <td>2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southwestair</th>\n",
       "      <td>2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jetblue</th>\n",
       "      <td>2361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancelled</th>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "words              \n",
       "united         4143\n",
       "flight         3873\n",
       "usairways      3051\n",
       "americanair    2957\n",
       "southwestair   2452\n",
       "jetblue        2361\n",
       "get            1334\n",
       "thanks         1072\n",
       "cancelled      1056\n",
       "service         956"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list = list()\n",
    "for sentence in df['cleaned_text'].values:\n",
    "    tokens = sentence.split()\n",
    "    for token in tokens:\n",
    "        words_list.append(token)\n",
    "\n",
    "df_words_list = pd.DataFrame(data={'words':words_list})\n",
    "df_words_list.groupby(by='words')['words'].agg(['count']).sort_values(by='count',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b35187",
   "metadata": {},
   "source": [
    "### 3. Use the cleaned dataframe from previous section inorder to build ML model as questioned below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771db55",
   "metadata": {},
   "source": [
    "### 3.a. Convert the text feature/column into numerical using Count-vectorization  (Marks-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42f17a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: use below count_vectorize  method definition\n",
    "count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "cvectors = count_vectorizer.fit_transform(df['cleaned_text'])\n",
    "cvectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afbf8dc",
   "metadata": {},
   "source": [
    "### 3.b. Convert the text  feature/column into numerical using TF-IDF (Marks-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b04f8c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: use below TfidfVectorizer method definition\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',stop_words='english', ngram_range=(1, 1))\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n",
    "tfidf_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d1fd5",
   "metadata": {},
   "source": [
    "### 3.c Split both Count-vectorirsed  & TF-IDF dataset into train & test set  with one fourth records being held for testing also ensure stratified sampling of traget i.e. airline_sentiment on both split ( Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed8ff379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>9178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "airline_sentiment       \n",
       "negative            9178\n",
       "neutral             3099\n",
       "positive            2363"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint  use the split method : train_test_split(vectorise_dataframe,Y,stratify=Y,test_size= )\n",
    "df.groupby(by='airline_sentiment')['airline_sentiment'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc629e4a-15f2-4b8a-9579-d370bbee9382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>3</td>\n",
       "      <td>virginamerica plus added commercials experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>3</td>\n",
       "      <td>americanair thank got different flight chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>1</td>\n",
       "      <td>americanair leaving 20 minutes late flight war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>2</td>\n",
       "      <td>americanair please bring american airlines bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>americanair money change flight answer phones ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>2</td>\n",
       "      <td>americanair 8 ppl need 2 know many seats next ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  airline_sentiment  \\\n",
       "0                    @VirginAmerica What @dhepburn said.                  2   \n",
       "1      @VirginAmerica plus you've added commercials t...                  3   \n",
       "2      @VirginAmerica I didn't today... Must mean I n...                  2   \n",
       "3      @VirginAmerica it's really aggressive to blast...                  1   \n",
       "4      @VirginAmerica and it's a really big bad thing...                  1   \n",
       "...                                                  ...                ...   \n",
       "14635  @AmericanAir thank you we got on a different f...                  3   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...                  1   \n",
       "14637  @AmericanAir Please bring American Airlines to...                  2   \n",
       "14638  @AmericanAir you have my money, you change my ...                  1   \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...                  2   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0                            virginamerica dhepburn said  \n",
       "1      virginamerica plus added commercials experienc...  \n",
       "2      virginamerica today must mean need take anothe...  \n",
       "3      virginamerica really aggressive blast obnoxiou...  \n",
       "4                     virginamerica really big bad thing  \n",
       "...                                                  ...  \n",
       "14635     americanair thank got different flight chicago  \n",
       "14636  americanair leaving 20 minutes late flight war...  \n",
       "14637  americanair please bring american airlines bla...  \n",
       "14638  americanair money change flight answer phones ...  \n",
       "14639  americanair 8 ppl need 2 know many seats next ...  \n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['airline_sentiment'] == 'positive', 'airline_sentiment' ] = 3\n",
    "df.loc[df['airline_sentiment'] == 'neutral', 'airline_sentiment' ]  = 2\n",
    "df.loc[df['airline_sentiment'] == 'negative', 'airline_sentiment' ] = 1\n",
    "df['airline_sentiment'] = df['airline_sentiment'].astype('int32')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "149f550b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10980, 15473), (3660, 15473), (10980,), (3660,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split count-vectorised dataset\n",
    "# 2 marks\n",
    "Xcnt = cvectors\n",
    "ycnt = df['airline_sentiment']\n",
    "Xcnt_train, Xcnt_test, ycnt_train, ycnt_test = train_test_split(Xcnt, ycnt, test_size=0.25, random_state=43)\n",
    "Xcnt_train.shape, Xcnt_test.shape, ycnt_train.shape, ycnt_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74f1f043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10980, 15203), (3660, 15203), (10980,), (3660,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split tf-idf dataset\n",
    "#2 marks\n",
    "Xtfidf = tfidf_vectors\n",
    "ytfidf = df['airline_sentiment']\n",
    "Xtfidf_train, Xtfidf_test, ytfidf_train, ytfidf_test = train_test_split(Xtfidf, ytfidf, test_size=0.25, random_state=43)\n",
    "Xtfidf_train.shape, Xtfidf_test.shape, ytfidf_train.shape, ytfidf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7cea9",
   "metadata": {},
   "source": [
    "### 3.d Build a basic logistic regression model ( LogisticRegression(solver='liblinear')) on Count-vectorize train set and find out its accuracy on Count-vectorize test set.  ( Marks-10 = 5 -training + 5-finding accuracy )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6719994f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7890710382513662"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hint:  use below LogisticRegression method\n",
    "lrcnt = LogisticRegression(solver='liblinear')\n",
    "lrcnt.fit(Xcnt_train, ycnt_train)\n",
    "# train lr on Count-vectorize trainset\n",
    "ycnt_pred = lrcnt.predict(Xcnt_test)\n",
    "# find accuracy on Count-vectorize test set \n",
    "accuracy_score(ycnt_test, ycnt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cdb2066-d311-4f66-9c4c-97793a6868dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 1, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ycnt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "153ab42f-cd23-4a12-a448-2c0648a9969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc157d5c-c052-48ed-8753-ef2243fd7eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.90      0.87      2284\n",
      "           2       0.63      0.54      0.58       774\n",
      "           3       0.77      0.67      0.72       602\n",
      "\n",
      "    accuracy                           0.79      3660\n",
      "   macro avg       0.75      0.71      0.72      3660\n",
      "weighted avg       0.78      0.79      0.78      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpt = classification_report(ycnt_test, ycnt_pred)\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8bc6a689-6ada-48f7-bfb5-0524fad39ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2061,  171,   52],\n",
       "       [ 284,  421,   69],\n",
       "       [ 122,   74,  406]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ycnt_test, ycnt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288099d2",
   "metadata": {},
   "source": [
    "### 3.e Build a basic logistic regression model ( LogisticRegression(solver='liblinear')) on TF-IDF train set and find out its accuracy on TF-IDF test set.  Which model has better accuracy ?(  Marks-10 = 5(training) + 5 (finding accuracy) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21351b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7669398907103825"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # train lr on TF-IDF train set\n",
    "lrtfidf = LogisticRegression(solver='liblinear')\n",
    "lrtfidf.fit(Xtfidf_train, ytfidf_train)\n",
    "# train lr on Count-vectorize trainset\n",
    "ytfidf_pred = lrtfidf.predict(Xtfidf_test)\n",
    "# find accuracy on Count-vectorize test set \n",
    "accuracy_score(ytfidf_test, ytfidf_pred)\n",
    "# find accuracy on TF-IDF  test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89a00bdd-44ac-4884-86d8-e7ba4bb6159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.96      0.85      2284\n",
      "           2       0.70      0.35      0.47       774\n",
      "           3       0.83      0.57      0.68       602\n",
      "\n",
      "    accuracy                           0.77      3660\n",
      "   macro avg       0.77      0.63      0.67      3660\n",
      "weighted avg       0.76      0.77      0.74      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpt = classification_report(ytfidf_test, ytfidf_pred)\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c5275101-a98a-4393-a907-2b1332f2ca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.96      0.85      2284\n",
      "           2       0.70      0.35      0.47       774\n",
      "           3       0.83      0.57      0.68       602\n",
      "\n",
      "    accuracy                           0.77      3660\n",
      "   macro avg       0.77      0.63      0.67      3660\n",
      "weighted avg       0.76      0.77      0.74      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpt = classification_report(ytfidf_test, ytfidf_pred)\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36273e0d-46be-42a9-8633-af3d87f7e1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2190,   63,   31],\n",
       "       [ 462,  274,   38],\n",
       "       [ 203,   56,  343]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytfidf_test, ytfidf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44351295-fabf-4dc4-a1fb-fa17bec1eedc",
   "metadata": {},
   "source": [
    "# CountVectorizer based model is performing compared to tfidf model for classes 1 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f0922-1ccc-44bf-8586-71870956ab95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
